---
title: "Intro to R"
subtitle: "8 Multiple OLS Regression"
author: "Merlin Schaeffer & Friedolin Merhout <br> Department of Sociology"
date: "`r Sys.Date()`"
output: 
  xaringan::moon_reader:
    chakra: "../template/remark-latest.min.js"
    css: ["../template/Merlin169.css"]
    lib_dir: libs
    # self_contained: true
    nature:
      highlightLanguage: r
      highlightStyle: zenburn
      highlightLines: true
      countIncrementalSlides: false
      ratio: '16:9'
---
```{r setup, include = FALSE}
library(RefManageR)
library(knitr)
library(equatiomatic)
library(dagitty) # Use the dagitty package
library(ggdag) # Neat visualization of DAGs

options(htmltools.dir.version = FALSE, servr.interval = 0.5, width = 115, digits = 3)
knitr::opts_chunk$set(
  collapse = TRUE, message = FALSE, fig.retina = 3, error = TRUE,
  warning = FALSE, cache = FALSE, fig.align = 'center',
  comment = "#", strip.white = TRUE, tidy = FALSE)

BibOptions(check.entries = FALSE, 
           bib.style = "authoryear", 
           style = "markdown",
           hyperlink = FALSE,
           no.print.fields = c("doi", "url", "ISSN", "urldate", "language", "note", "isbn", "volume"))
myBib <- ReadBib("./../../intRo.bib", check = FALSE)

xaringanExtra::use_xaringan_extra(c("tile_view", "tachyons"))
xaringanExtra::use_panelset()
```
# Let's get ready

```{r}
# Add packages to library
library(tidyverse) # Add the tidyverse package to my current library.
library(haven) # Handle labelled data.
library(ggplot2) # Allows us to create nice figures.
library(estimatr) # Allows us to estimate (cluster-)robust standard errors.
library(texreg) # Allows us to make nicely-formatted Html & Latex regression tables. #<<
library(broom) # Allows us to turn parts of model objects into tibbles. #<<
library(modelr) # Model predictions (can also do resampling).
```

```{r include = FALSE}
# Load previously downloaded ESS round 10 data
ESS <- read_spss("./../../assets/ESS10.sav")
```

---
class: clear

```{r}
ESS <- ESS %>% transmute( # Create new variables and keep only those
    cntry = as_factor(cntry) %>% fct_relevel("France"), # Country of interview #<<
    gndr = as_factor(gndr), # Gender
    agea = zap_labels(agea), # Age
    facntr = as_factor(facntr), # Father born in cntry
    mocntr = as_factor(mocntr), # Mother born in cntry
    imwbcnt = max(imwbcnt, na.rm = TRUE) - zap_labels(imwbcnt), # Immigrants make country better (0) - worse (10) place
    nwspol_hrs = zap_labels(ESS$nwspol)/60, # Daily politital news consumption in hours #<<
    rtrd = as_factor(rtrd), # Last 7 days: retired #<<
    pspwght = pweight*dweight,
    eduyrs = case_when( # Education
      eduyrs > 21 ~ 21, # Recode to max 21 years of edu.
      eduyrs < 9 ~ 9, # Recode to min 9 years of edu.
      TRUE ~ zap_labels(eduyrs))) %>% # Make it numeric, then
  dplyr::filter( # Keep only respondents with native-born parents in four countries
    facntr == "Yes" & mocntr == "Yes",
    cntry %in% c("France", "Estonia", "Finland", "Hungary"))
```

---
# Design matrix

```{r}
# Design matrix (i.e., tibble of the variables going into our model)
ESS <- ESS %>%
  select(cntry, imwbcnt, eduyrs, nwspol_hrs, rtrd, gndr, agea, pspwght) %>%
  mutate(cntry = fct_drop(cntry)) %>% # Drop unused cntry factor levels
  drop_na() # Casewise deletion.
```


---

# The limits of bivariate OLS

--

.push-left[
Bivariate OLS allows us to express a continuous outcome as linear function of *one* continuous or categorical predictor.
```{r}
# Estimate a weighted linear OLS model.
ols1 <- lm_robust(
  formula = imwbcnt ~ nwspol_hrs, #<<
  data = ESS, weights = pspwght)
summary(ols1) # Give a summary of the main results.
```
]

--

.push-right[
But with observational data, we oftentimes have *multiple* potential explanations/predictors of interest.
```{r}
# Estimate an alternative bivariate OLS model.
ols2 <- lm_robust(
  formula = imwbcnt ~ rtrd, #<<
  data = ESS, weights = pspwght)
summary(ols2) # Give a summary of the main results.
```
]



---

# The limits of bivariate OLS


.push-left[
So, what to do if our alternative explanations are correlated?
```{r}
# Estimate a model of our focal predictors.
ols3 <- lm_robust(
  formula = nwspol_hrs ~ rtrd, #<<
  data = ESS, weights = pspwght)
summary(ols3) # Give a summary of the main results.
```
]

--

.push-right[
```{r echo = FALSE, out.width='100%', fig.height = 4, fig.width = 5}
dagify( # Define the DAG
  # Define the theoretical causal model
  Xeno ~ News + Retired + Conf,
  News ~ Retired + Conf,
  # Add labels
  labels = c("Xeno" = "Xenophobia",
             "News" = "News Consumption",
             "Retired" = "Retirement"),
  # Specify coordinates for the graph
  coords = list(
    x = c(News = 0, Retired = 0, Xeno = 1),
    y = c(News = 0, Retired = 1, Xeno = 0.5))
) %>%
  ggdag(text = FALSE, use_labels = "label") +
  theme_dag_blank()
```
]


---

# The solution: multiple OLS

--

.left-column[
To identify the causal effect of news consumption on perceptions of immigrants' societal impact, we need to account for the confounding influence of retirement status.
```{r echo = FALSE, out.width='100%', fig.height = 4, fig.width = 5}
dagify( # Define the DAG
  # Define the theoretical causal model
  Xeno ~ News + Retired + Conf,
  News ~ Retired + Conf,
  # Add labels
  labels = c("Xeno" = "Xenophobia",
             "News" = "News Consumption",
             "Retired" = "Retirement"),
  # Specify coordinates for the graph
  coords = list(
    x = c(News = 0, Retired = 0, Xeno = 1),
    y = c(News = 0, Retired = 1, Xeno = 0.5))
) %>%
  ggdag(text = FALSE, use_labels = "label") +
  theme_dag_blank()
```
.backgrnote[
A confounder is a common cause of both the focal predictor $x_{i1}$ (e.g., news consumption) and the outcome $y_i$ (e.g., xenophobia). Counfounder bias is: $\mathbb{E}(\tilde{\beta_{x_{1}}}) = \beta_{x_{1}} + \color{orange}{\beta_{x_{2}} \frac{\text{Cov}(x_{i1},x_{i2})}{\text{Var}(x_{i1})}}.$
]
]

--

.right-column[ 
In R, we run multiple OLS by adding additional predictors with `+` to the right-hand side of our model formula.
.panelset[
.panel[.panel-name[Bivariate (biased) model]
.font90[
```{r}
lm_robust(imwbcnt ~ nwspol_hrs, data = ESS, weights = pspwght) %>%
  summary()
```
]]
.panel[.panel-name[Multiple (corrected) model]
.font90[
```{r}
lm_robust(imwbcnt ~ nwspol_hrs + rtrd, data = ESS, weights = pspwght) %>%
  summary()
```
]]
]
```{r echo = FALSE}
ols4 <- lm_robust(
  formula = imwbcnt ~ nwspol_hrs + rtrd, #<<
  data = ESS, weights = pspwght)
```
]

---

# A "comprehensive" model


.push-left[
Let's assume perceptions of immigrants' societal impact can be explained by respondents' *news consumption*, *retirement status*, *gender*, and *country of residence*. 
]


---

# A "comprehensive" model


.push-left[
Let's assume perceptions of immigrants' societal impact can be explained by respondents' *news consumption*, *retirement status*, *gender*, and *country of residence*. We can model this as follows:

.font80[
```{r}
# Estimate a comprehensive multiple OLS model.
ols5 <- lm_robust(
  formula = imwbcnt ~ nwspol_hrs + rtrd + gndr + cntry , #<<
  data = ESS, weights = pspwght)
summary(ols5) # Give a summary of the main results.
```
]
]

--

.push-right[
.center[.content-box-green[
What does the model tell us about the causal effect of news consumption?]]
]


---

# A "comprehensive" model


.push-left[
Let's assume perceptions of immigrants' societal impact can be explained by respondents' *news consumption*, *retirement status*, *gender*, and *country of residence*. We can model this as follows:

.font80[
```{r}
# Estimate a comprehensive multiple OLS model.
ols5 <- lm_robust(
  formula = imwbcnt ~ nwspol_hrs + rtrd + gndr + cntry , #<<
  data = ESS, weights = pspwght)
summary(ols5) # Give a summary of the main results.
```
]
]

.push-right[
.center[.content-box-green[
What does the model tell us about the causal effect of news consumption?]]

.center[.content-box-green[
How do we interpret the coefficient for retirement status?]]
]



---

# A "comprehensive" model


.push-left[
Let's assume perceptions of immigrants' societal impact can be explained by respondents' *news consumption*, *retirement status*, *gender*, and *country of residence*. We can model this as follows:

.font80[
```{r}
# Estimate a comprehensive multiple OLS model.
ols5 <- lm_robust(
  formula = imwbcnt ~ nwspol_hrs + rtrd + gndr + cntry , #<<
  data = ESS, weights = pspwght)
summary(ols5) # Give a summary of the main results.
```
]
]

.push-right[
.center[.content-box-green[
What does the model tell us about the causal effect of news consumption?]]

.center[.content-box-green[
How do we interpret the coefficient for retirement status?]]

.center[.alert[But isn't there a way to make finding these answers easier?]]
]


---
# Regression tables

--

.font90[
```{r warning = FALSE, message = FALSE}
# Regression table of model objects ols1, ols4, and ols5; report standard errors, not confidence intervals.
texreg::screenreg(list(ols1, ols4, ols5), include.ci = FALSE) 
```
]

---

# Regression tables

.push-left[
.font90[
```{r eval = FALSE}
# Regression table with labelled predictors
htmlreg(list(ols1, ols4, ols5), include.ci = FALSE,
        custom.coef.names = c("Intercept", 
                              "News consumption (hours)", 
                              "Retired", "Women", 
                              "Estonia", "Finland", "Sweden"),
        caption = "My regression table", 
        caption.above = TRUE,
        single.row = TRUE)
```
]]

--

.push-right[
.font70[
```{r results = 'asis', echo = FALSE}
htmlreg(list(ols1, ols4, ols5), include.ci = FALSE, doctype = FALSE,
        custom.coef.names = c("Intercept", 
                              "News consumption (hours)", 
                              "Retired", "Women", 
                              "Estonia", "Finland", "Sweden"),
        caption = "My regression table", 
        caption.above = TRUE,
        single.row = TRUE) # Html table
```
]]


---
# Further processing of model results

 We can also turn multiple regression model results into a tibble containing coefficients and inferential statistics using `broom:tidy()`.
```{r}
tidy(ols5) 
```

---
# Remember: regression results are data too.

And then process the data in our tibble to make it presentable.

```{r out.width='50%', fig.align='center', dpi = 350, fig.height = 3, fig.width = 5}
(plotdata <- ols5 %>% tidy() %>% # Use the ols5 model object, then tidy it, then
   mutate(term = fct_recode(factor(term), # Recode predictor names, then
                            "Intercept" = "(Intercept)",
                            "News consumption (hours)" = "nwspol_hrs",
                            "Retired" = "rtrdMarked",
                            "Women" = "gndrFemale",
                            "Estonia" = "cntryEstonia",
                            "Finland" = "cntryFinland",
                            "Sweden" = "cntryHungary"),
          predictor = case_when( # Identify explanatory and confounding variables
            term %in% c("News consumption (hours)", "Retired") ~ "Predictor",
            TRUE ~ "Potential confounder"))) %>% 
  select(term, estimate, conf.low, conf.high, predictor) # Keep only relevant info.
```

---
class: clear
# Coefficient plots .font60[Great for multiple regression results]

.panelset[
.panel[.panel-name[Plot]
```{r out.width='60%', fig.height = 4, fig.width = 6, echo = FALSE}
ggplot(data = plotdata,
       aes(x = reorder(term, estimate), # Sort predictors based on coef size  #<<
           y = estimate, 
           ymin = conf.low, ymax = conf.high,
           color = predictor)) +
  geom_hline(yintercept = 0, # Null-hypothesis line.
             color = "#901A1E", lty = "dashed") + 
  geom_pointrange() + # Coefs with 95% CI.
  coord_flip() + 
  theme_minimal() +
  # Axis title: greek beta.
  labs(title = "Coefficients from multiple OLS regression",
       subtitle = "predicting perception of immigrants' societal impact",
       y = expression(beta), 
       x = "") +
  theme(legend.position="bottom",
        legend.title=element_blank())
```
]
.panel[.panel-name[Code]
```{r fig.show = "hide"}
ggplot(data = plotdata,
       aes(x = reorder(term, estimate), # Sort predictors based on coef size  #<<
           y = estimate,   #<<
           ymin = conf.low, ymax = conf.high,   #<<
           color = predictor)) +
  geom_hline(yintercept = 0, # Null-hypothesis line.
             color = "#901A1E", lty = "dashed") + 
  geom_pointrange() + # Coefs with 95% CI.
  coord_flip() + 
  theme_minimal() +
  # Axis title: greek beta.
  labs(y = expression(beta), x = "") +
  theme(legend.position="bottom",
        legend.title=element_blank())
```
]]

---
class: clear
# Further processing of model results .font60[Several models]
```{r}
(plotdata <- bind_rows( # Stack several tibbles on top of each other into one tibble, #<<
  tidy(ols1), tidy(ols4), # turn the two models into tibbles, #<<
  .id = "model" # Identify which model the tibbles came from. #<<
)) 
```

---
# Further processing of model results

```{r}
(plotdata <- bind_rows(tidy(ols1), tidy(ols4), # Stack the data of two model objects into one tibble.
                       .id = "model") %>% # Identify which model the data came from, then
   # Get rid of the intercept, because it is so large compared to the other coefficients.
   dplyr::filter(term != "(Intercept)") %>%
   mutate(
     model = case_when(model == 1 ~ "Model 1", # Rename model identifier.
                       model == 2 ~ "Model 2"),
     term = fct_recode(factor(term), # Recode predictor names, then
                       "News consumption (hours)" = "nwspol_hrs",
                            "Retired" = "rtrdMarked")) %>% 
   select(term, estimate, conf.low, conf.high, model)) # Keep only relevant info.
```

---
class: clear
# Coefficient plots .font60[Good alternative to regression tables]

.panelset[
.panel[.panel-name[Plot]
```{r out.width='60%', fig.height = 4, fig.width = 6, echo = FALSE}
ggplot(data = plotdata, 
       aes(x = reorder(term, estimate),
           y = estimate, 
           ymin = conf.low, ymax = conf.high,
           shape = model)) +
  geom_hline(yintercept = 0, # Null-hypothesis line.
             color = "#901A1E", lty = "dashed") + 
  geom_pointrange(# Coefs & 95% CI. #<<
    position = position_dodge(width=0.5)) + #<<
  coord_flip() + 
  theme_minimal() +
  # Axis title: greek beta.
  labs(y = expression(beta), 
       x = "") +
  theme(legend.position="bottom",
        legend.title=element_blank(),
        legend.box = 'vertical')
```
]
.panel[.panel-name[Code]
```{r coefplot2, fig.show = "hide"}
ggplot(data = plotdata, 
       aes(x = reorder(term, estimate),
           y = estimate, 
           ymin = conf.low, ymax = conf.high,
           shape = model)) +
  geom_hline(yintercept = 0, # Null-hypothesis line.
             color = "#901A1E", lty = "dashed") + 
  geom_pointrange(# Coefs & 95% CI. #<<
    position = position_dodge(width=0.5)) + #<<
  coord_flip() + 
  theme_minimal() +
  # Axis title: greek beta.
  labs(y = expression(beta), 
       x = "") +
  theme(legend.position="bottom",
        legend.title=element_blank(),
        legend.box = 'vertical')
```
]]


---
# Model predictions .font60[From multiple regression]

.panelset[
.panel[.panel-name[The multiple OLS model]
.push-left[
**Step 1**: Fit multiple OLS model to (survey) data.
```{r}
ols <- lm_robust(
  formula = imwbcnt ~ nwspol_hrs + rtrd + gndr + cntry,
  data = ESS, weights = pspwght)
```
]
.push-right[
```{r Coefplot2, out.width='100%', fig.height = 4, fig.width = 6, echo = FALSE}
plotdata2 <- ols %>%
  tidy() %>% # Turn results into a tibble,
  mutate( # Rename variables for the plot.
    term = fct_recode(factor(term), # Recode predictor names, then
                            "Intercept" = "(Intercept)",
                            "News consumption (hours)" = "nwspol_hrs",
                            "Retired" = "rtrdMarked",
                            "Women" = "gndrFemale",
                            "Estonia" = "cntryEstonia",
                            "Finland" = "cntryFinland",
                            "Sweden" = "cntryHungary"),) %>%
  filter(term != "Intercept")


ggplot(data = plotdata2, aes(y = estimate, 
                            # Order by effect size
                            x = reorder(term, estimate))) +
  geom_hline(yintercept = 0, color = "red", lty = "dashed") +
  # Point with error-bars,
  geom_pointrange(aes(min = conf.low, max = conf.high)) +
  coord_flip() + # Flip Y- & X-Axis,
  labs(
    title = "Coefficients from multiple OLS regression",
    subtitle = "predicting perception of immigrants' societal impact",
    x = "",
    # Write Greek beta into axis title.
    y = expression("Estimate of"~beta)) +
  theme_minimal()
```
]]
.panel[.panel-name[Predictions]
.push-left[
**Step 2**: Generate a synthetic tibble with theoretically-informative values. `modelr::data_grid()` generates a tibble with all combinations of the provided variables.

```{r}
(pred_data <- ESS %>%
   # Generate theoretically-informative 
   # synthetic tibble for predictions.
   data_grid(nwspol_hrs = seq_range(nwspol_hrs, 20), #<<
             rtrd = names(sort(table(ESS$rtrd), decreasing = TRUE))[1], #<<
             gndr = names(sort(table(ESS$gndr), decreasing = TRUE))[1], #<<
             cntry = names(sort(table(ESS$cntry), decreasing = TRUE))[1]) #<<
)
```
]
.push-right[
**Step 3**: Compute predictions from model for synthetic data. Given data, what $\hat{y}$ does our model predict?

```{r}
(pred_data <- predict( #<<
  ols, newdata = pred_data, #<<
  interval = "confidence", level = 0.95)$fit %>% #<<
   as_tibble() %>% # Turn into a tibble, then
   bind_cols(pred_data, .)) # Add to the synthetic data.
```
]]
.panel[.panel-name[Visualization]
.push-left[
**Step 4**: Visualize predicted values.
```{r Predplot, fig.show = 'hide'}
pred_data %>% 
  ggplot(aes(y = fit, x = nwspol_hrs)) +
  geom_ribbon(aes(ymin = lwr, ymax = upr), alpha = 0.5) +
  geom_line() +
  labs(
    title = "Predictions for immigrants perceived societal impact",
    x = "By hours of political news consumption",
    y = "Predicted perceived impact") +
  theme_minimal()
```
]
.push-right[
```{r ref.label = "Predplot", out.width='100%', fig.height = 4, fig.width = 6, echo = FALSE}
```
]]]


---
# Model predictions .font60[Varying multiple predictors]

.panelset[
.panel[.panel-name[Predictions]
.push-left[
Generate a synthetic tibble with theoretically-informative values varying two predictors. `modelr::data_grid()` generates a tibble with all combinations of the provided variables.

```{r}
(pred_data <- ESS %>%
   # Generate theoretically-informative 
   # synthetic tibble for predictions.
   data_grid(nwspol_hrs = seq_range(nwspol_hrs, 20), #<<
             rtrd = names(table(ESS$rtrd)), #<<
             gndr = names(sort(table(ESS$gndr), decreasing = TRUE))[1],
             cntry = names(sort(table(ESS$cntry), decreasing = TRUE))[1])
)
```
]
.push-right[
Compute predictions from model for synthetic data. Given data, what $\hat{y}$ does our model predict?

```{r}
(pred_data <- predict(
  ols, newdata = pred_data,
  interval = "confidence", level = 0.95)$fit %>%
   as_tibble() %>% # Turn into a tibble, then
   bind_cols(pred_data, .)) # Add to the synthetic data.
```
]]
.panel[.panel-name[Visualization]
.push-left[
Visualize predicted values.
```{r Predplot2, fig.show = 'hide'}
pred_data %>% 
  ggplot(aes(y = fit, x = nwspol_hrs,
             color = rtrd, fill = rtrd)) +
  geom_ribbon(aes(ymin = lwr, ymax = upr), alpha = 0.5) +
  geom_line() +
  labs(
    title = "Predictions for immigrants perceived societal impact",
    x = "By hours of political news consumption",
    y = "Predicted perceived impact",
    color = "Retirement\nstatus",
    fill = "Retirement\nstatus") +
  theme_minimal()
```
]
.push-right[
```{r ref.label = "Predplot2", out.width='100%', fig.height = 4, fig.width = 6, echo = FALSE}
```
]]]

---
class: inverse
# General lessons

1. Multiple linear OLS models allow us to specify more complex theorized data generating processes. We specify additional predictors with `+` on the right-hand side of our model formula.
2. R allows us to communicate our model results efficiently via coefficient plots and prediction plots.
3. Everything in R is an object and you can always further process it. For instance, regression results are also just data, which you can visualize, table, join to other data, etc.

---
class: inverse
# Important functions

1. `estimatr::lm_robust()` estimates (bivariate and multiple) OLS regression with heteroscedasticity-robust standard errors (or cluster-robust standard errors if you wish).
2. `broom::tidy()`: Turn model results into tibble for further processing.
4. `dplyr::bind_rows()`: Add the rows of a data frames to another data frame that has equal columns/variables.
